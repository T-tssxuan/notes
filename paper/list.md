## My paper list
1. Massive Exploration of Neural Machine Translation Architectures
2. Convolutional Neural Network Architectures for Matching Natural Language Sentences 
3. Short Text Similarity with Word Embeddings 
4. A Convolutional Neural Network for Modelling Sentences
5. Natural Language Processing (almost) from Scratch(2011)
6. A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval (Microsoft ir)
7. Modeling Interestingness with Deep Neural Networks(Microsoft ir)
8. Wide & Deep Learning for Recommender Systems (23)
9. Session-based Recommendations with Recurrent Neural Networks (25)
10. Hybrid Recommender System based on Autoencoders (4)
11. Collaborative denoising auto-Encoders for top-N recommender systems 
12. Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding (233)
13. A neural probabilistic language model (2325)
14. Efficient Estimation of Word Representations in Vector Space (3448)
15. Label Embedding Trees for Large Multi-Class Tasks (242)
16. Kernel dependency estimation (170)
17. Space/Time Trade-offs in Hash Coding with Allowable Errors(6752)
18. Bloom Filters { A Tutorial, Analysis, and Survey(12)
19. An Improved Construction for Counting Bloom Filters(244)
20. Hash Kernels for Structured Data(149)
21. Feature Hashing for Large Scale Multitask Learning(409)
22. Solving Multiclass Learning Problems via Error-Correcting Output Codes(2659)
23. Multi-Label Prediction via Compressed Sensing(264)
24. Information-theoretical label embeddings for large-scale image classification KNN(27)
25. Relations Between Two Sets of Variates (4339)
26. Label Embedding Trees for Large Multi-Class Tasks(42)
27. BinaryConnect: Training Deep Neural Networks with binary weights during propagations(138)
28. Generating Sequences With Recurrent Neural Networks(584)
29. Hierarchical Probabilistic Neural Network Language Model(434)
30. On the Properties of Neural Machine Translation: Encoder-Decoder Approaches(404)
31. Neural Machine Translation by Jointly Learning to Align and Translate(2014, 1444)
32. Noise-contrastive estimation: A new estimation principle for unnormalized statistical models (144)
33. Training Products of Experts by Minimizing Contrastive Divergence(2791)
34. Estimation of Non-Normalized Statistical Models by Score Matching(237)
35. Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics(158)
36. Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion(1537)
37. Contractive Auto-Encoders: Explicit Invariance During Feature Extraction(463)
38. Efficient Learning of Sparse Representations with an Energy-Based Model(728)
39. Semi-Supervised Learning with Ladder Networks(139)
40. Stacked What-Where Auto-encoders(66)
41. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks(DCGAN 2015, 423)
42. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift(1648)
43. Stacked What-Where Auto-encoders
44. Adam: A Method for Stochastic Optimization(2535)
45. Backpropagation applied to handwritten zip code recognition(2373)
46. LONG SHORT-TERM MEMORY(4734)
47. Interaction Networks for Learning about Objects, Relations and Physics(11)
48. Learning multiagent communication with backpropagation(26)
49. Social lstm: Human trajectory prediction in crowded spaces (30)
50. Memory Networks(330)
51. End-To-End Memory Networks(270)
52. Neural turing machines(350)
53. Mastering the Game of Go with Deep Neural Networks and Tree Search(1079)
54. Attention is all you need
55. Wasserstein GAN(80)
56. Improved Training of Wasserstein GANs(25)
57. Began: Boundary equilibrium generative adversarial  networks 
58. Maximum-Likelihood Augmented Discrete Generative Adversarial Networks(8)
59. Boundary-Seeking Generative Adversarial Networks(4)
60. SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient(4)
61. GANS for Sequences of Discrete Elements with the Gumbel-softmax Distribution(5)
62. Linguistic Regularities in Continuous Space Word Representations(1007)
63. Simple statistical gradient-following algorithms for connectionist reinforcement learning(1500)
64. Adversarial Learning for Neural Dialogue Generation(16)
65. The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables(26)
66. GANS for Sequences of Discrete Elements with the Gumbel-softmax Distribution(6)
67. Adversarial Generation of Natural Language
68. Style Transfer from Non-Parallel Text by Cross-Alignment
69. Language Generation with Recurrent Generative Adversarial Networks without Pre-training
70. Auto-Encoding Variational Bayes (860)
71. Categorical Reparameterization with Gumbel-Softmax
72. A Hybrid Convolutional Variational Autoencoder for Text Generation(4)
73. Adversarial Autoencoders(2015, 58)
74. Deep and Hierarchical Implicit Models(8, 2017)
75. Adversarial Variational Bayes: Unifying Variational Autoencoders and Generative Adversarial Networks (, 2017)
76. PixelGAN Autoencoders (, 2017)
77. Learning Distributed Representations of Sentences from Unlabelled Data(30, 2016)
78. Extracting and Composing Robust Features with Denoising Autoencoders(1588, 2008)
79. Semi-supervised Sequence Learning(80, 2015)
80. A note on the evaluation of generative models(92, 2015)
81. The painting fool sees! new projects with the automated painter (2015, 4)
82. Incorporating Characteristics of Human Creativity into an Evolutionary Art Algorithm(88, 2007)
83. Before A Computer Can Draw, It Must First Learn To See(2016, 1)
84. Inceptionism: Going Deeper into Neural Networks(, 2015)
85. Creativity Versus the Perception of Creativity in Computational Systems(154, 2008)
86. Inceptionism: Going deeper into neural networks (, 2015)
87. Generative Adversarial Text to Image Synthesis(2016, 90)
88. Professor Forcing: A New Algorithm for Training Recurrent Networks(16, 2016)
89. Unsupervised representation learning with deep convolutional generative adversarial networks(423, 2015)
90.  note on the evaluation of generative models (100, 2016)
91. Optimization Methods for Large-Scale Machine Learning (36, 2016)
92. Sequence to Sequence Learning with Neural Networks(2014, 2210)
93. Neural Machine Translation by Jointly Learning to Align and Translate(2014, 1496)
94. Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation (2014, 1484)
95. Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation(2016, 116)
96. Effective Approaches to Attention-based Neural Machine Translation(2016, 119)
97. Exploring the Limits of Language Modeling(2016, 102)
98. Factorization tricks for LSTM networks(2017, 2)
99. Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer(2017, 15)
100. Structured Attention Networks(2017, 8)
101. A Decomposable Attention Model for Natural Language Inference(2016, 28)
102. Can Active Memory Replace Attention? (2016, 2)
103. Neural Machine Translation in Linear Time (2016, 12)
104. Convolutional Sequence to Sequence Learning(2017, 2)  cnn translation
105. Gradient Flow in Recurrent Nets: the Difficulty of Learning Long-Term Dependencies (2001, 420)
106. Long Short-Term Memory-Networks for Machine Reading(2016, 53)
107. Learning Accurate, Compact, and Interpretable Tree Annotation (2006, 730)
108. A Structured Self-attentive Sentence Embedding (2017, 6)
109. Neural GPUs Learn Algorithms(2015, 66)
110. Generating Sequences With Recurrent Neural Networks(2013, 594)
111. Dropout: A Simple Way to Prevent Neural Networks from Overfitting (2014, 2788)
112. Image Denoising Via Sparse and Redundant Representations Over Learned Dictionaries(2006, 3229)
113. Image inpainting (2000, 3403)
114. Super-resolution: a comprehensive survey(2004, 129)
115. Natural image colorization (2007, 109)
116. A survey: Image segmentation techniques(2015, 16)
117. Context Encoders: Feature Learning by Inpainting(2016, 96)
118. Image Super-Resolution Using Deep Convolutional Networks(2016, 119)
119. Colorful Image Colorization(2016, 73)
120. Deep Colorization (2016, 40)
121. Fully Convolutional Networks for Semantic Segmentation (2016, 1801)
122. Conditional Generative Adversarial Nets(2014, 129)
123. Image-to-Image Translation with Conditional Adversarial Networks (2016, 79)
124. Perceptual losses for real-time style transfer and super-resolution (2016, 131)
125. Generating Images with Perceptual Similarity Metrics based on Deep Networks (2016, 54)
126. Super-Resolution with Deep Convolutional Sufficient Statistics (2015, 17)
127. Image De-raining Using a Conditional Generative Adversarial Network(2017, )
128. Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network (2016, 68)
129. Clearing the Skies: A deep network architecture for single-image rain removal (2016, 3)
130. Restoring An Image Taken Through a Window Covered with Dirt or Rain (2013, 79)
131. Deep Joint Rain Detection and Removal from a Single Image (2016, )
132. Generative Face Completion (2017, 1)
133. Learning Hierarchical Features for Scene Labeling (2013, 979)
134. Learning Deconvolution Network for Semantic Segmentation (2015, 376)
135. Predicting Depth, Surface Normals and Semantic Labels with a Common Multi-Scale Convolutional Architecture (2014, 176)
136. Unsupervised Learning of Visual Structure using Predictive Generative Networks (2015, 15)
137. Generative Visual Manipulation on the Natural Image Manifold (2016)
138. Neural Photo Editing with Introspective Adversarial Networks (2015, 15)
139. A Neural Algorithm of Artistic Style (2015, 236)
140. f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization (2016, 55)
141. On distinguishability criteria for estimating generative models (2014, 55)
142. Quick Training of Probabilistic Neural Nets by Importance Sampling (2003, )
143. Adaptive Importance Sampling to Accelerate Training of a Neural Probabilistic Language Model (2008, 61)
144. IMPROVING GENERATIVE ADVERSARIAL NETWORKS WITH DENOISING FEATURE MATCHING (2017, 5)
145. It Takes (Only) Two: Adversarial Generator-Encoder Networks (2017, 3)
146. Variational Inference: A Review for Statisticians (2016, 49)
147. Likelihood-free inference via classification (2012, 5)
148. Learning in Implicit Generative Models (2016, 25)
149. Generative Adversarial Nets from a Density Ratio Estimation Perspective (2016, 11)
150. Variational Inference using Implicit Distributions (2017, 3)
151. Unrolled Generative Adversarial Networks (2017, 29)
152. Stochastic Backpropagation and Approximate Inference in Deep Generative Models (2014, 411)
153. Statistical inference for noisy nonlinear ecological dynamic systems
154. Likelihood-free inference by ratio estimation (2016, 1)
155. Adversarial Variational Bayes: Unifying Variational Autoencoders and Generative Adversarial Networks (2017, 17)
156. A note on the evaluation of generative models  (2015, 100)
157. Conditional Image Synthesis With Auxiliary Classifier GANs (2016, 30)
158. Deep Learning Face Attributes in the Wild (2015, 207)
159. Comparison of Maximum Likelihood and GAN-based training of Real NVPs (2017, 3)
160. Adversarially Learned Inference (2016, 49)
161. Show, attend and tell: Neural image caption generation with visual attention (2015, 789)
162. Learning Deep Representations of Fine-grained Visual Descriptions (2016, 34)
163. Multimodal Deep Learning (2011, 784)
164. Improved Multimodal Deep Learning with Variation of Information (2014, 51)
165. Weakly-supervised Disentangling with Recurrent Transformations for 3D View Synthesis (2016, 49)
166. Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks (2015, 252)
167. Exploring Models and Data for Image Question Answering (2015, 124)
168. Generating images from captions with attention (2016, 29)
169. DRAW: A Recurrent Neural Network For Image Generation (2015, 385)
170. Conditional generative adversarial nets for convolutional face generation (2015, 28)
171. NIPS 2016 Tutorial: Generative Adversarial Networks (2017, 5)
172. Do GANs actually learn the distribution? An empirical study (2017, )
173. Generalization and Equilibrium in Generative Adversarial Nets (GANs)
174. Efficient Density Estimation via Piecewise Polynomial Approximation (2013, 39)
175. Very Deep Convolutional Networks for Text Classification (2016, 29)
176. Learning Hierarchical Features for Scene Labeling (2013, 990) - text classifer
177. Visualizing and Understanding Convolutional Networks (2014, 2077)
178. Visualizing and Understanding Neural Models in NLP (2015, 44)
179. Understanding Neural Networks through Representation Erasure (2016, 6)
180. Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank (2013, 1296)
181. ADADELTA: An Adaptive Learning Rate Method (2012, 996)
182. Long Short-Term Memory Over Tree Structures (2015, 54)
183. Controllable Text Generation (2017, 3)
184. Baselines and Bigrams: Simple, Good Sentiment and Topic Classification (2012, 320)
185. Latent Dirichlet Allocation (2003, 19260)
186. Document Embedding with Paragraph Vectors (2015, 29)
187. Ensemble of Generative and Discriminative Techniques for Sentiment Analysis of Movie Reviews (2014, 50)
188. Text Understanding from Scratch (2015, 109)
189. Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks (2015, 330)
190. Composition in Distributional Models of Semantics (2010, 496)
191. Compositional Matrix-Space Models for Sentiment Analysis (2011, 94)
192. Multi-Step Regression Learning for Compositional Distributional Semantics (2013, 95)
193. From Word Embeddings To Document Distances (2015, 120)
194. Improving Word Representations via Global Context and Multiple Word Prototypes (2012, 574)
195. Learning with Marginalized Corrupted Features (2013, 83)
196. Dropout Training as Adaptive Regularization (2013, 136)
197.  Marginalized Denoising Auto-encoders for Nonlinear Representations (2014, 65)
198. Extracting and Composing Robust Features with Denoising Autoencoders (2015, 1650)
199. Skip-Thought Vectors (2015, 278)
200. Visualizing Data using t-SNE (2008, 2792)
201. Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books (2015, 57)
202. Building Machines That Learn and Think Like People (2016, 73)
203. Better Word Representations with Recursive Neural Networks for Morphology (2013, 242)
204. Non-Negative Randomized Word Embeddings (2017, )
205. Multimodal word meaning induction from minimal exposure to natural text (2017, )
206. Generating text with recurrent neural networks (2011, 443)
207. BLEU: a Method for Automatic Evaluation of Machine Translation (2002, 6637)
208. Classifying Relations by Ranking with Convolutional Neural Networks (2015, 93)
209. Generating sentences from a continuous space (2016, 87)
210. Adversarial evaluation of dialogue models (2016, 1)
211. Adversarial learning for neural dialogue generation (2017, 16)
212. REFERENCE-AWARE LANGUAGE MODELS(2016, 3)
213. Incorporating Copying Mechanism in Sequence-to-Sequence Learning (2016, 49)
214. Pointing the Unknown Words (2016, 44)
215. Pointer sentinel mixture models  (2016, 24)
216. Data recombination for neural semantic parsing (2016, 16)
217. Neural machine translation with reconstruction (2017)
218. OpenNMT: Open-Source Toolkit for Neural Machine Translation (2017)
219. Capacity and Trainability in Recurrent Neural Networks (2016, 3)
220. Recurrent Highway Networks (2016, 32)
221. Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling (2016, 7)
222. Using the Output Embedding to Improve Language Models (2016, 11)
223. A Theoretically Grounded Application of Dropout in Recurrent Neural Networks (2015, 75)
224. Recurrent Dropout without Memory Loss (2016, 15)
225. On Using Very Large Target Vocabulary for Neural Machine Translation
226. Noise-contrastive estimation: A new estimation principle for unnormalized statistical models
227. Good Question! Statistical Ranking for Question Generation (2010, )
228. Generating Natural Questions About an Image (2016, 10)
229. SQuAD: 100,000+ Questions for Machine Comprehension of Text(2016, 134)
230. MS MARCO: A Human Generated MAchine Reading COmprehension Dataset (2016, 22)
231. The Importance of Being Important: Question Generation(2008, )
232. Summarizing Source Code using a Neural Attention Model (2016, )
233. Deep Questions without Deep Understanding (2010, )
234. Generating Factoid Questions With Recurrent Neural Networks: The 30M Factoid Question-Answer Corpus (2016, )
235. Abstractive Sentence Summarization with Attentive Recurrent Neural Networks (2016, 16)
236. All-but-the-Top: Simple and Effective Postprocessing for Word Representations (2017, 2)
237. Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings (2016, 26)
238. A Tutorial on Principal Component Analysis (2014, 1699)
239. Measuring the influence of long range dependencies with neural network language models (2012, 23)
240. Extensions of recurrent neural network language model (2011, 399)
241. The Fixed-Size Ordinally-Forgetting Encoding Method for Neural Network Language Models (2015, 13)
242. How to Construct Deep Recurrent Neural Networks (2013, 204)
243. Exploring the Limits of Language Modeling (2016, 160)
244. Strategies for Training Large Vocabulary Neural Language Models(2015, 16)
245. Hierarchical Probabilistic Neural Network Language Model(, 462)
246. A Survey of Neural Network Techniques for Feature Extraction from Text(2017, )
247. Cache Based Recurrent Neural Network Language Model Inference for First Pass Speech Recognition(2014, )
248. Recurrent continuous translation models(2014, 356)
249. An overview of gradient descent optimization algorithms(ruder blog)
250. On the difficulty of training recurrent neural networks (2014, 644)
251. Recurrent Convolutional Neural Networks for Text Classification
252. NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE
253. word2vec Parameter Learning Explained
254. Hierarchical Attention Networks for Document Classification
255. A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification
256. Reinforcement learning in the brain
257. Learning Semantic Similarity for Very Short Texts
258. Towards Neural Machine Translation with Latent Tree Attention(2017)
259. Bilingual Word Embeddings for Phrase-Based Machine Translation
260. An Empirical Comparison of Exact Nearest Neighbour Algorithms
261. Learning to Compose Neural Networks for Question Answering
262. Hybrid computing using a neural network with dynamic external memory
263. Q-RNN Experiments: Language Modeling
264. Quasi-Recurrent Neural Networks
265. Tying word Vectors and Word Classifiers: A loss Framework for Language Modeling
266. Use small units, Sennrich, Haddow
267. RNN for words+something else for characters
268. Pointing the unknown words
269. A neural probabilistic language model (2003, 2600)
270. On the properties of neural machine translation: Encoder–Decoder approaches (2014, 551)
271. Maxout Networks (2014, 681)
272. Generating sequences with recurrent neural networks (2013, 759)
273. A Survey of Monte Carlo Tree Search Methods (2012, 863)
274. Generating sentences from a continuous space (2015, 111)
275. Zero-resource machine translation by multimodal encoder-decoder network with multimedia pivot(2017, 3)
276. Improving neural machine translation models with monolingual data (2015, 83)
277. Domain-Adversarial Training of Neural Networks (2015, 141)
278. Word Translation Without Parallel Data(2017, )
279. Google's Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation(2016, 49)
280. Extracting and composing robust features with denoising autoencoders (2008, 1864)
281. Style Transfer from Non-Parallel Text by Cross-Alignment(2017, 1)
282. Toward Controlled Generation of Text (2017, 18)
283. Enriching Word Vectors with Subword Information(2016, 190)
284. Improving Vector Space Word Representations Using Multilingual Correlation(2014, 194)
285. Normalized word embedding and orthogonal transform for bilingual word translation 
286. Offline bilingual word vectors, orthogonal transformations and the inverted softmax(2017, 9)
287. Learning bilingual word embeddings with (almost) no bilingual data(2017, 1)
288. Adversarial training for unsupervised bilingual lexicon induction (2017, 2)
289. Improving zero-shot learning by mitigating the hubness problem （2015, 49）
290. Billion-scale similarity search with gpus (2017, 14)
291. Parseval networks: Improving robustness to adversarial examples (2017, )
292. The earth mover’s distance as a metric for image retrieval (2000, 3080)
293. A Discriminative CNN Video Representation for Event Detection
294. A Discriminative CNN Video Representation for Event Detection
